import pickle
import numpy as np
import cv2
import os
from cv2 import resize
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score



gray_image=[]
count =0
def get_pixel(img, center, x, y):
    new_value = 0
    try:
        if img[x][y] >= center:
            new_value = 1
    except:
        pass
    return new_value

def lbp_calculated_pixel(img, x, y):
    center = img[x][y]
    val_ar = []
    # top_left
    val_ar.append(get_pixel(img, center, x - 1, y - 1))
    # top
    val_ar.append(get_pixel(img, center, x - 1, y))
    # top_right
    val_ar.append(get_pixel(img, center, x - 1, y + 1))
    # right
    val_ar.append(get_pixel(img, center, x, y + 1))
    # bottom_right
    val_ar.append(get_pixel(img, center, x + 1, y + 1))
    # bottom
    val_ar.append(get_pixel(img, center, x + 1, y))
    # bottom_left
    val_ar.append(get_pixel(img, center, x + 1, y - 1))
    # left
    val_ar.append(get_pixel(img, center, x, y - 1))
    # Now, we need to convert binary
    # values to decimal
    power_val = [1, 2, 4, 8, 16, 32, 64, 128]
    val = 0
    for i in range(len(val_ar)):
        val += val_ar[i] * power_val[i]
    return val

FrequencyList =[]
arr=[]

train_dir = 'D:/FaceExpression/train'
for r, dirs, files in os.walk(train_dir):
    val = len(files)
    arr.append(val)
    for ii in range(0, val):
        img = cv2.imread(r + '/' + files[ii])
        height, width, _ = img.shape
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        new_gray_image = resize(gray, (48, 48))
        img_lbp = np.zeros((height, width),np.uint8)
        for i in range(0, height):
            for j in range(0, width):
                img_lbp[i, j] = lbp_calculated_pixel(new_gray_image, i, j)
        img_lbp=img_lbp.flatten()
        b=np.bincount(img_lbp)
        FrequencyList.append(b)

x_train = np.array(FrequencyList)

print(x_train.shape)
print("x_train end")
label1 = np.zeros(arr[1])
label2 = np.zeros(arr[2])+1
label3 = np.zeros(arr[3])+2
label4 = np.zeros(arr[4])+3
label5 = np.zeros(arr[5])+4
label6 = np.zeros(arr[6])+5
label7 = np.zeros(arr[7])+6

y_train = np.concatenate((label1,label2,label3,label4,label5,label6,label7),axis=0)
print(y_train.shape)
print("y_train end")

#######################################################------------- Train Model End ------------#############################################

#######################################################------------- Test Model Start ------------###########################################

# FrequencyList_test =[]
# arr_test=[]
#
# test_dir = 'D:/FaceExpression/test'
# count=0
# for r, dirs, files in os.walk(test_dir):
#     val_test = len(files)
#     arr_test.append(val_test)
#     for ii in range(0, val_test):
#         img_test = cv2.imread(r + '/' + files[ii])
#         height_test, width_test, _ = img_test.shape
#         gray_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2GRAY)
#         new_gray_image_test = resize(gray_test, (48, 48))
#         img_test_lbp = np.zeros((height_test, width_test),np.uint8)
#         for i in range(0, height_test):
#             for j in range(0, width_test):
#                 img_test_lbp[i, j] = lbp_calculated_pixel(new_gray_image_test, i, j)
#         img_test_lbp=img_test_lbp.flatten()
#         b=np.bincount(img_test_lbp)
#         FrequencyList_test.append(b)
# x_test = np.array(FrequencyList_test)
# print(x_test.shape)
# print("x_test end")
#
# label1 = np.zeros(arr_test[1])
# label2 = np.zeros(arr_test[2])+1
# label3 = np.zeros(arr_test[3])+2
# label4 = np.zeros(arr_test[4])+3
# label5 = np.zeros(arr_test[5])+4
# label6 = np.zeros(arr_test[6])+5
# label7 = np.zeros(arr_test[7])+6
#
# y_test = np.concatenate((label1,label2,label3,label4,label5,label6,label7),axis=0)
# print(y_test.shape)
# print("y_test end")



logi = LogisticRegression()
logi.fit(x_train,y_train)

filename = 'finalized_model.sav'
pickle.dump(logi, open(filename, 'wb'))
# attr = logi.__dict__
# New_attr = attr
# keys = New_attr.keys()
#
# New_attr['coef_'] = attr['coef_'].tolist()
# New_attr['classes_'] = attr['classes_'].tolist()
# New_attr['n_iter_'] = attr['n_iter_'].tolist()
# New_attr['intercept_'] = attr['intercept_'].tolist()
#
# # Writing JSON file
# json_file = "model.json"
# json.dump(New_attr, codecs.open(json_file, 'w', encoding='utf-8'),
#     sort_keys=True, indent=4)
#
# # Reading the JSON file...
# obj_text = codecs.open(json_file, 'r', encoding='utf-8').read()
# b_new = json.loads(obj_text)
#
# logi = LogisticRegression()
# print(b_new)
# logi.__dict__ = dict(b_new)
#
# logi.coef_ = np.array(logi.coef_)
# logi.classes_ = np.array(logi.classes_)
# logi.n_iter_ = np.array(logi.n_iter_)
# logi.intercept_ = np.array(logi.intercept_)
# ////////////////////////////////////////////////////////////////////


# img = cv2.imread('C:\\Users\\debam\\Pictures\\Camera Roll\\riju.jpg')
#
# image = resize(img, (48, 48))
# height, width, _ = image.shape
# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
# new_gray_image = resize(gray, (48, 48))
# img_lbp = np.zeros((height, width),np.uint8)
# for i in range(0, height):
#     for j in range(0, width):
#         img_lbp[i, j] = lbp_calculated_pixel(new_gray_image, i, j)
# img_lbp=img_lbp.flatten()
# b=np.bincount(img_lbp)
# FrequencyList=[]
# FrequencyList.append(b)
#
# x_test = np.array(FrequencyList)
#
# prediction=logi.predict(x_test)
# prediction_number = int(prediction[0])
# label_map = ['angry','disgust','fear','happy','neutral','sad','surprise']
#
# # prediction = np.argmax(prediction)
# print(label_map[prediction_number])
# final_prediction=label_map[prediction]
# print(prediction)
# print(accuracy_score(y_test,prediction))



# /////////////////////////////////Scalable solution//////////////////////////////

# x, y = make_classification(random_state=42)
# x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)
# pipe = make_pipeline(StandardScaler(), LogisticRegression())
# pipe.fit(x_train, y_train)
# steps=[('standardscaler', StandardScaler()),('logisticregression', LogisticRegression())]
# print(pipe.score(x_test, y_test))
